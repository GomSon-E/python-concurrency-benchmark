# 비동기 vs 동기 API 호출 성능 비교

- **총 요청 수:** 200개

---

### [1] 비동기 방식 테스트

- ✓ 완료: 200개 응답
- ⏱ 소요 시간: 2.11초

### [2] 동기 방식 테스트 중

- ✓ 완료: 20개 응답
- ⏱ 소요 시간: 12.68초 (20개 기준)

## 📊 결과 비교

| 방식 | 소요 시간 |
|------|----------|
| 비동기 (200개) | 2.11초 |
| 동기 예상 (200개) | 126.84초 |

🚀 **비동기가 약 60.0배 빠름!**

---

# 비동기 vs 멀티스레드 API 호출 성능 비교

- **총 요청 수:** 200개
- **스레드 풀 워커 수:** 50개

---

### [1] 비동기 방식 테스트

- ✓ 완료: 200개 응답
- ⏱ 소요 시간: 3.44초
- 💾 메모리: 현재 1.22MB, 피크 3.57MB

### [2] 멀티스레드 방식 테스트

- ✓ 완료: 200개 응답
- ⏱ 소요 시간: 5.61초
- 💾 메모리: 현재 0.60MB, 피크 2.91MB

## 📊 결과 비교

| 방식 | 소요 시간 | 피크 메모리 |
|------|----------|------------|
| 비동기 (asyncio + aiohttp) | 3.44초 | 3.57MB |
| 멀티스레드 (ThreadPool) | 5.61초 | 2.91MB |

- ⏱ **속도:** 비동기가 약 1.63배 빠름!
- 💾 **메모리:** 멀티스레드가 약 1.23배 적게 사용!

---

# 멀티스레드 워커 수 증가에 따른 성능 변화 테스트

- **총 요청 수:** 200개
- **테스트 워커 수:** [50, 100, 200, 1000]

---

### [기준] 비동기 방식 테스트

- ✓ 완료: 2.31초 | 피크 메모리: 3.96MB

### [워커 50개] 멀티스레드 테스트

- ✓ 완료: 5.53초 | 피크 메모리: 2.78MB | 비동기 대비 2.39배

### [워커 100개] 멀티스레드 테스트

- ✓ 완료: 5.67초 | 피크 메모리: 4.42MB | 비동기 대비 2.45배

### [워커 200개] 멀티스레드 테스트

- ✓ 완료: 5.77초 | 피크 메모리: 7.29MB | 비동기 대비 2.49배

### [워커 1000개] 멀티스레드 테스트

- ✓ 완료: 5.66초 | 피크 메모리: 7.20MB | 비동기 대비 2.45배

## 📊 결과 요약

| 워커 수 | 소요 시간 | 피크 메모리 | 비동기 대비 |
|--------|----------|------------|------------|
| 비동기 | 2.31초 | 3.96MB | 1.00x (기준) |
| 50 | 5.53초 | 2.78MB | 2.39x |
| 100 | 5.67초 | 4.42MB | 2.45x |
| 200 | 5.77초 | 7.29MB | 2.49x |
| 1000 | 5.66초 | 7.20MB | 2.45x |

## 📈 분석

- 워커 수 50 → 1000 (20.0배 증가)
- 속도 향상: 0.98배 (이상적이라면 20.0배)
- 효율성: 4.9%

❌ **테스트한 워커 수 범위 내에서 비동기 성능에 도달하지 못함**

⚠️ **수확체감 현상 발생!** 워커 수 증가 대비 성능 향상이 크지 않음

> 수확 체감(Diminishing Returns)은 경제학 법칙으로, 다른 생산요소는 고정된 채 특정 생산요소(예: 노동력, 비료)만 추가 투입할 때, 생산량의 증가분(한계 생산량)이 점차 감소하는 현상을 말합니다.

---

# 멀티스레드 vs 멀티프로세스 CPU 바운드 성능 비교

- **CPU 코어 수:** 12개
- **작업 수:** 100개
- **연산 복잡도:** 50000 ~ 150000 범위 소수 계산

---

### [1] 동기 방식 (순차 실행) 테스트

- ✓ 완료: 16.75초 | 피크 메모리: 0.03MB

### [2] 멀티스레드 방식 (12 workers) 테스트

- ✓ 완료: 20.24초 | 피크 메모리: 0.32MB
- 📈 동기 대비 0.83배 속도

### [3] 멀티프로세스 방식 (12 workers) 테스트

- ✓ 완료: 3.08초 | 피크 메모리: 0.40MB
- 📈 동기 대비 5.43배 속도

## 📊 결과 요약

| 방식 | 소요 시간 | 피크 메모리 | 속도 향상 |
|-----|----------|------------|----------|
| 동기 (순차) | 16.75초 | 0.03MB | 1.00x |
| 멀티스레드 | 20.24초 | 0.32MB | 0.83x |
| 멀티프로세스 | 3.08초 | 0.40MB | 5.43x |

## 📈 분석

### GIL (Global Interpreter Lock)

Python의 GIL은 한 번에 하나의 스레드만 Python 바이트코드 실행

- **멀티스레드:** GIL로 인해 CPU 작업은 실제로 병렬 실행 안 됨
  - → 스레드 전환 오버헤드만 추가되어 오히려 느려질 수 있음
- **멀티프로세스:** 각 프로세스가 독립적인 GIL 보유
  - → 진정한 병렬 실행 가능, CPU 코어 수만큼 성능 향상

---

- 이론적 최대 속도 향상 (코어 수): **12배**
- 멀티스레드 실제 속도 향상: **0.83배** (효율: 6.9%)
- 멀티프로세스 실제 속도 향상: **5.43배** (효율: 45.3%)

⚠️ **멀티스레드는 CPU 바운드 작업에서 거의 효과 없음** (GIL 때문)

✅ **멀티프로세스가 멀티스레드보다 6.6배 빠름!**

---

# 동기가 멀티스레드보다 빠른 이유

| 방식 | 소요 시간 |
|-----|----------|
| 동기 | 16.75초 |
| 멀티스레드 | 20.24초 (오히려 3.5초 더 느림!) |

**핵심: GIL + 오버헤드**

### 동기 (순차 실행)

```
작업1 ████████ → 작업2 ████████ → 작업3 ████████
```

- GIL 경합 없음
- 컨텍스트 스위칭 없음
- 단순하게 순차 실행

### 멀티스레드 (12 workers)

```
스레드1 ██░░██░░██░░  (GIL 대기)
스레드2 ░░██░░██░░██  (GIL 대기)
스레드3 ░░░░██░░██░░  (GIL 대기)
...
```

- 12개 스레드가 GIL 하나를 두고 경쟁
- 실제로는 한 번에 1개만 실행됨
- 스레드 전환 오버헤드가 계속 발생
- 결과: 순차 실행 + 오버헤드 = 더 느림

## 멀티스레드의 오버헤드

| 오버헤드 | 설명 |
|---------|-----|
| GIL 경합 | 12개 스레드가 GIL 획득을 위해 경쟁 |
| 컨텍스트 스위칭 | OS가 스레드 간 전환하는 비용 |
| 스레드 생성/관리 | ThreadPool 관리 비용 |
| Lock 대기 | GIL 해제/획득 반복 |

## CPU 바운드 작업에서 멀티스레드는

- 병렬 실행 안 됨 (GIL 때문에 한 번에 1개만)
- 순차 실행과 동일한 작업량 + 추가 오버헤드
- 결과적으로 순차 실행보다 느림